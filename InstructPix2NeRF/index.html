<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <title>InstructPix2NeRF</title>
    <meta name="author" content="Jianhui Li">
    <meta name="description" content="Project page of InstructPix2NeRF paper, 2024">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<!--     <link rel="icon" type="image/png" href="eccv_logo.png"> -->
    <!-- Format -->
    <link rel="stylesheet" href="./css/bootstrap.min.css">
    <link rel="stylesheet" href="./css/font-awesome.min.css">
    <link rel="stylesheet" href="./css/codemirror.min.css">
    <script src="./js/jquery.min.js"></script>
    <script src="./js/codemirror.min.js"></script>
    <script src="./js/clipboard.min.js"></script>

  </head>

  <body>
    <div class="container" id="main">
        <div class="row">
            <h1 class="col-md-12 text-center">
                InstructPix2NeRF: Instructed 3D Portrait Editing from a Single Image  <br /> 
         
<!--                 <small>
                    
                </small> -->
            </h1>
        </div>
        
        <div class="row">
            <div class="col-md-12 text-center">
                <ul class="list-inline">
                    <li>
                         Jianhui Li
                    </li>
              
                    <li>
                        Shilong Liu
                    </li>

                    <li>
                        Zidong Liu
                    </li>
                  
                    <li>
                        Yikai Wang
                    </li>
                  
                    <li>
                        Kaiwen Zheng
                    </li>
                  
                    <li>
                        Jinghui Xu
                    </li>

                    <li>
                        Jianmin Li
                    </li>
                  
                    <li>
                        Jun Zhu
                    </li>
                </ul>
                <ul>
                    <li>
                        Tsinghua University
                    </li>
                </ul>
            </div>
        </div>
      
        <div class="row">
                <div class="col-md-4 col-md-offset-4 text-center">
                    <ul class="nav nav-pills nav-justified">
                        <li>
                            <a href="https://arxiv.org/abs/2311.02826">
                            <h4><strong>Paper</strong></h4>
                                
                            </a>
                        </li>
                        <li>

                            <a href="https://github.com/mybabyyh/InstructPix2NeRF">
                            <h4><strong>Code</strong></h4>
                            </a>
                        </li>
                      
                    </ul>
                    
                    <ul class="list-inline">
                        <li style="color:#F00">
                            <h4><strong>Accepted in ICLR 2024</strong></h4>
                        </li>
                      
                    </ul>
                </div>
        </div>
      
      
        <!-- ##### Abstract #####-->
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
              
                <h3>
                    Abstract
                </h3>
                <p class="text-justify">
                    With the success of Neural Radiance Field (NeRF) in 3D-aware portrait editing, a variety of works have achieved promising results regarding both quality and 3D consistency. However, these methods heavily rely on per-prompt optimization when handling natural language as editing instructions. Due to the lack of labeled human face 3D datasets and effective architectures, the area of human-instructed 3D-aware editing for open-world portraits in an end-to-end manner remains under-explored. To solve this problem, we propose an end-to-end diffusion-based framework termed $\textbf{InstructPix2NeRF}$, which enables instructed 3D-aware portrait editing from a single open-world image with human instructions. At its core lies a conditional latent 3D diffusion process that lifts 2D editing to 3D space by learning the correlation between the paired images' difference and the instructions via triplet data. With the help of our proposed token position randomization strategy, we could even achieve multi-semantic editing through one single pass with the portrait identity well-preserved. Besides, we further propose an identity consistency module that directly modulates the extracted identity signals into our diffusion process, which increases the multi-view 3D identity consistency. Extensive experiments verify the effectiveness of our method and show its superiority against strong baselines quantitatively and qualitatively.
                </p>
            </div>
        </div>

 

        <!-- ##### Approach #####-->
   
     <div class="row">     
       
     <div class="col-md-8 col-md-offset-2">
          <h3>
              Approach 
          </h3>   
           <br />
     <table width="100%" style="margin: 15pt auto; text-align: center;">      
      <tr>
          <td>
            <img src="./images/pipeline.jpg" alt="original image"  width="100%" />
          </td>    
      </tr>      
    </table>          
       
    </div> 
    </div>     
      
     <!-- ##### Results #####-->
    <div class="row">     
       
     <div class="col-md-8 col-md-offset-2">
          <h3>
              Results 
          </h3>   
           <br />
     <table width="100%" style="margin: 15pt auto; text-align: center;">      
      <tr>
          <td>
            <img src="./images/head.jpg" alt="original image"  width="100%" />
          </td>    
      </tr>      
    </table>          
       
    </div> 
    </div>  
     <!-- ##### Demo #####-->
    <div class="row">     
       
     <div class="col-md-8 col-md-offset-2">
          <h3>
              Real-time Editing 
          </h3>   
           <br />
     <table width="100%" style="margin: 15pt auto; text-align: center;">      
      <tr>
        <td>
          <img src="./images/more1.jpg" alt="original image"  width="100%" />
        </td>    
        <td>
          <img src="./images/more2.jpg" alt="original image"  width="100%" />
        </td>  
      </tr>      
    </table>    
    <div class="col-md-8 col-md-offset-2">
         <h3>
             More Results 
         </h3>   
          <br />
    <table width="100%" style="margin: 15pt auto; text-align: center;">      
     <tr>
         <td>
           <video width="100%"  controls>
               <source src="images/more1.jpg" type="video/mp4">
           </video>
         </td>    
     </tr>      
   </table>        
       
    </div> 
    </div>  
   
    
        <!-- ##### BibTex #####-->
        <hr>
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    BibTeX
                </h3>
 
                <div class="row align-items-center">
                    <div class="col py-3">
                        <pre class="border">             
                            @article{li2023instructpix2nerf,
                                title={InstructPix2NeRF: Instructed 3D Portrait Editing from a Single Image},
                                author={Li, Jianhui and Liu, Shilong and Liu, Zidong and Wang, Yikai and Zheng, Kaiwen and Xu, Jinghui and Li, Jianmin and Zhu, Jun},
                                journal={arXiv preprint arXiv:2311.02826},
                                year={2023}
                              }
</pre>
                    </div>
                </div>
              
    
          </div>
          
        </div>

    </div>
</body>
</html>
